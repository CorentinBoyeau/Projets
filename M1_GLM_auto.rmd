---
title: "Projet Assurance non-vie"
subtitle: GLM sur la survenance de sinistres
author: Boyeau Corentin; Faroui Ramzi; Rousseau Aurélien
date: 25 mars 2020
output:   
  bookdown::html_document2:
    fig_caption: yes
    number_sections: yes
    toc: yes
linkcolor: red
header-includes:
- \usepackage[francais]{babel}
- \usepackage{float}
- \usepackage{booktabs}
---


```{r , echo=FALSE, warning=FALSE , message=FALSE}
library(ggplot2)
library(ggthemes)
library(gridExtra)
library(dplyr)
library(caret)
library(ROCR)
library(car)

```

# Importation et description des données

Notre base de données comprend 7483 observations. Une observation correspondant à un assuré. Le dataset va comptabiliser le nombre de sinistres d'un assuré ainsi que certaines caractéristiques de celui-ci, décrites ci-dessous. 


Les deux variables que l'on cherchera à prédire sont :

  * **Clm_Count** : Nombre de sinistres de l'assuré dans l'année (variable utilisée pour le modèle Poisson).    
  
  La deuxième variable que l'on va chercher à prédire étant une variable que l'on va créer et qui est définie comme suit : 
  
  * **occurence** : Survenance d'un sinistre. La variable vaut 1 si l'assuré a eu au moins un sinistre et 0 sinon (variable utilisée pour le modèle binomial).  



Notre jeu de données contient 7 variables explicatives, chacune divisée en catégories : 

  * **Exp_weights** : Fraction de l'année depuis laquelle la police d'assurance fait effet
  * **SexInsured** : genre de l'assuré (F: Femme, H:Homme, U:Non Spécifié)
  * **Female** : =1 si l'assuré est une femme, =0 sinon (homme ou non spécifié) 
  * **VehicleType** : Le type de véhicule assuré (9 catégories : A : Automobile, T:Truck, M:Motorcycle ...)
  * **NCD** : No Claims Discount. Plus le rabais est élevé, meilleurs sont les antécédents en matière d'accidents. 6 catégories (0,10,20,30,40,50)
  * **AgeCat** : Age de l'assuré divisé en 7 catégories (18-21,22-25,26-35,36-45,46-55,56-65,66+)
  * **VAgeCat** : Age du véhicule en années, divisé en 7 catégories (0,1,2,3-5,6-10,11-15,16+)

```{r , echo=FALSE, warning=FALSE , message=FALSE}
data <- read.csv("SingaporeAuto.csv", header=T, sep=';')


# On renomme les modalités des variables pour qu'elles soient plus explicites
data$AgeCat <- factor(data$AgeCat, levels = c(0,2,3,4,5,6,7), labels = c("18-21","22-25","26-35","36-45","46-55","56-65","66+"))
data$VAgeCat <- factor(data$VAgeCat, levels = c(0,1,2,3,4,5,6), labels = c("0","1","2","3-5","6-10","11-15","16+"))

data$Female=as.factor(data$Female)
data$NCD=as.factor(data$NCD)
data$Clm_Count=as.factor(data$Clm_Count)

summary(data)
str(data)

data$Clm_Count=as.integer(data$Clm_Count)-1

#Création variable occurence : 

data$occurence <- as.factor(ifelse(data$Clm_Count >= 1 ,"1","0"))   #O si pas d'accident, 1 si au moins un accident

#Séparation dataset

set.seed(2)
sample <- sample(nrow(data), 2000)

data_train<- data[-sample,]
data_test <- data[sample,]
```


On a également décidé de séparer notre dataset en deux parties. Une première, "data_train", de 5483 observations sur laquelle on entraînera nos modèle. Un autre dataset, "data_test", de 2000 observations sur lequel on réalisera les prédictions. On pourra ainsi comparer nos prédictions avec les données réelles. 


# Analyse descriptive - Impact des variables sur la survenance d'un sinistre


## Impact du genre de l'assuré 


On peut tout d'abord s'intéresser au lien entre le genre de l'assuré et survenance d'un sinistre. Dans notre cas l'information est difficilement exploitable puisque le genre n'est pas précisé pour 3638 observations (soit une observation sur deux). Considérons tout de même la variable *Female* valant 1 lorsque l'assuré est une femme et 0 lorsque c'est un homme ou lorsqu'on ne sait pas.

```{r , echo=FALSE, warning=FALSE , message=FALSE}



ggplot (data_train, aes(occurence, fill=Female)) +
  geom_bar( position = "fill")+
  theme_few()+
  xlab("Survenance d'un sinistre")+
  ylab("Effectifs")+
  scale_fill_discrete(name="Sexe")+
  scale_y_continuous(labels = scales::percent)+
  ggtitle("Sexe vs Survenance")
```

Etonnamment le sexe ne semble pas être corrélé avec la survenance d'un sinistre, mais compte tenu du nombre très important de données manquantes il est impossible d'extraire de réelles conclusions de ce résultat.

## Impact du type de véhicule

```{r , echo=FALSE, warning=FALSE , message=FALSE}


ggplot (data_train, aes(occurence, fill=VehicleType)) +
  geom_bar( position = "fill")+
  theme_few()+
  xlab("Survenance d'un sinistre")+
  ylab("Effectifs")+
  scale_fill_discrete(name="Type de véhicule")+
  scale_y_continuous(labels = scales::percent)+
  ggtitle("Type de véhicule vs Survenance")
```

Le type de véhicule ne semble toujours pas être corrélé avec les sinistres. Une exception existe cependant peut-être pour le type de véhicule "A" qui a proportionnellement un peu plus d'accidents que le type "G", c'est deux classes étant les représentées. De plus, on ne dispose pas d'assez de données pour la plupart des autres types de véhicules pour que les différences soient réellement significatives.   

## Impact du bonus NCD

```{r , echo=FALSE, warning=FALSE , message=FALSE}


ggplot (data_train, aes(occurence, fill=NCD)) +
  geom_bar( position = "fill")+
  theme_few()+
  xlab("Survenance d'un sinistre")+
  ylab("Effectifs")+
  scale_fill_discrete(name="No Claims Discount")+
  scale_y_continuous(labels = scales::percent)+
  ggtitle("NCD vs Survenance")
```

Le bonus NCD a clairement une relation avec la variable occurence, les personnes sans bonus ont proportionnellement plus de sinistres que les personnes avec bonus. 

## Impact de l'âge de l'assuré

```{r, echo=FALSE , warning=FALSE , message=FALSE}


ggplot (data_train, aes(occurence, fill=AgeCat)) +
  geom_bar( position = "fill")+
  theme_few()+
  xlab("Survenance d'un sinistre")+
  ylab("Effectifs")+
  scale_fill_discrete(name="Age de l'assuré")+
  scale_y_continuous(labels = scales::percent)+
  ggtitle("Age de l'assuré vs Survenance")
```

L'âge de l'assuré ne semble pas être beaucoup corrélé avec le nombre de sinistres. Nous ne pouvons pas établir de liens de corrélation entre les deux variables à partir de ces résultats. 

## Impact de l'âge de la voiture

```{r , echo=FALSE, warning=FALSE , message=FALSE}


ggplot (data_train, aes(occurence, fill=VAgeCat)) +
  geom_bar( position = "fill")+
  theme_few()+
  xlab("Survenance d'un sinistre")+
  ylab("Effectifs")+
  scale_fill_discrete(name="Age du véhicule")+
  scale_y_continuous(labels = scales::percent)+
  ggtitle("Age du véhicule vs Survenance")
```

Les véhicules vieux de deux ans semblent avoir plus d'accidents que les autres. Inversement, les vieux véhicules de plus de 11 ans, semblent en avoir moins. Il semblerait qu'une relation de corrélation existe entre les deux variables.




# GLM Poisson

Notre premier modèle linéaire généralisé va chercher à prédire le nombre de sinistres survenu, via l'intermédiaire de la variable Clm_Count. Nous allons pour cela utiliser la loi de Poisson car la variable à prédire est positive, discrète et non binaire. On a alors :

 * $Y_i|X_i$ qui suit une loi de Poisson
 * $log(E[Y_i|X_i]) = X_i^T\beta$


## GLM avec toutes les variables

Dans cette première partie nous allons utiliser toutes les variables explicatives à disposition pour construire le modèle suivant.

Dans ce modèle nous allons ajouter un offset.  
En effet soit la variable "Exp_weights" correspondant à l’exposition de l'assuré durant l'année, c’est-à-dire la fraction de l'année durant laquelle le contrat de l’assuré est valable. Plus la valeur de la variable est grande, plus le nombre de sinistres a de chances de l’être aussi. Il est donc plus raisonnable de normaliser la variable à prédire selon cette fraction.

Ainsi on a désormais que : $log(E[\frac{Y_i}{\omega_i}|X_i]) = X_i^T\beta$

Ce qu'on peut réécrire :  $log(\frac{E[Y_i|X_i]}{\omega_i}) = X_i^T\beta$

On a donc finalement : $log(E[Y_i|X_i])=log(\omega_i)+X_i^T\beta$

L'offset peut être vu comme une nouvelle variable du modèle de régression avec un coefficient  $\beta$ constant égal à 1:

$log(E[Y_i|X_i]) = (X_i')^T\beta'$  avec $X_i' = (log\omega_i,X_i^T)^T$  et  $\beta' = (1, \beta^T)^T$



```{r , echo=FALSE, warning=FALSE , message=FALSE}

fit <- glm(formula = Clm_Count ~ VehicleType + Female +NCD + AgeCat + VAgeCat + offset(log(Exp_weights)) , data = data_train, family = poisson())
summary(fit)

```

Quantile d'une Khi2 à 5456 Ddl au degré de confiance de 95% :

```{r , echo=FALSE, warning=FALSE , message=FALSE}

qchisq(0.95,5456)

```

 * Nous remarquons tout d'abord que la déviance est inférieure au quantile de la loi du Khi-deux associée pour une confiance de 95%. De plus le modèle est mieux ajusté que le modèle comprenant seulement l'intercept puisque la déviance est plus faible dans ce modèle. La déviance de notre modèle semble bonne.

 * En revanche très nombreuses variables ne sont pas significatives (pvalue > 0,05). Ceci signifiant qu’on ne rejette pas les hypothèses de nullité de nombreux coefficients.

Ce modèle n’est donc pas optimal. Nous devons établir un processus de sélection de variables.


## Sélection  des variables 

Nous allons essayer de sélectionner les variables de manière optimale.

### Sélection par analyse de la déviance

Premièrement, nous allons sélectionner les variables grâce à la table de l'analyse de la déviance.  

```{r , echo=FALSE, warning=FALSE , message=FALSE}

anova(fit, test = "Chisq")

```

A la première ligne, on commence par considérer le modèle comprenant uniquement la constante, puis à chaque ligne on ajoute la variable indiquée dans la première colonne. 

Par exemple, la 4ème ligne correspond au modèle contenant la constante, la variable VehicleType, la variable Female et la variable NCD. On peut observer dans la dernière colonne la p-value du test de rapport de vraisemblance donnée par la colonne Resid.Dev et le nombre de degré de liberté par la colonne Resid.Df.

Cependant ce tableau ne nous donne pas une vision globale des modèles et ne permet pas de vérifier directement la significativité de chaque variable. Pour ce faire, on peut utiliser la fonction Anova du package "car" : 

```{r , echo=FALSE, warning=FALSE , message=FALSE}

library(car)
Anova(fit, test.statistic = "LR", type = 3)

```

Selon ce test, nous devrions donc garder les variables NCD et VAgeCat.

### Sélection à partir de l'AIC

Deuxièmement, nous allons sélectionner les variables en utilisant un autre indicateur : l'AIC. Nous allons regarder quel modèle le minimise. C'est pourquoi nous utilisons la fonction "step" en utilisant un raisonnement backward. La fonction va alors prendre le modèle avec toutes les variables et retirer étape par étape les variables afin d'obtenir un modèle avec un AIC minimisé. On obtient les résultats suivants :

```{r , echo=FALSE, warning=FALSE , message=FALSE}

step(fit, direction = "backward")

```


Les résultats des deux méthodes s'accordent, on décide alors de retirer les variables Female, VehicleType et AgeCat, puisque les variables NCD et VAgeCat sont les deux seules variables significatives.



## GLM Poisson optimisé

On construit alors le modèle suivant avec les variables sélectionnées précédemment :

```{r , echo=FALSE, warning=FALSE , message=FALSE}

fit_opti <- glm(formula = Clm_Count ~ NCD + VAgeCat  + offset(log(Exp_weights)), data = data_train, family = poisson())
summary(fit_opti)

```

Nous avons dans ce modèle un AIC plus faible que dans le précédent ainsi qu'un plus grand nombre de variables significatives, le modèle est donc bien amélioré de ce point de vue. 


# GLM Binomiale

Notre deuxième modèle linéaire généralisé va chercher à prédire si un sinistre va survenir, via l'intermédiaire de la variable occurence que l'on a créée. Nous allons pour cela utiliser la loi binomiale car la variable à prédire est positive et binaire. On a alors :

 * $Y_i|X_i$ qui suit une loi de Bernoulli 
 * $logit(E[Y_i|X_i]) = X_i^T\beta$ avec $logit(p)=log(\frac{p}{1-p})$


## GLM avec toutes les variables

Dans cette première partie nous allons utiliser toutes les variables explicatives à disposition pour construire le modèle:

```{r , echo=FALSE, warning=FALSE , message=FALSE}

reg <- glm(formula = occurence ~ VehicleType + Female +NCD + AgeCat + VAgeCat , data = data_train, family = binomial(link = "logit"))
summary(reg)

```

Quantile d'une Khi2 à 5456 Ddl au degré de confiance de 95%

```{r , echo=FALSE, warning=FALSE , message=FALSE}

qchisq(0.95,5456)

```

 * Nous remarquons tout d'abord que la déviance est inférieure au quantile de la loi du Khi-deux associée pour une confiance de 95%. De plus le modèle est mieux ajusté que le modèle comprenant juste la constante puisque la déviance est plus faible dans ce modèle. La déviance de notre modèle semble bonne.
 
 * En revanche nous avons un grand nombre de variables non significatives (pvalue > 0,05). Ceci signifiant qu’on ne rejette pas les hypothèses de nullité de nombreux coefficients.

Ce modèle n’est donc pas optimal. Nous devons établir, comme précédemment, un processus de sélection de variables.


## Sélection  des variables 


### Sélection par analyse de la déviance

Comme pour le modèle de Poisson, nous allons procéder par analyse de la déviance. On peut donc désormais utiliser directement la fonction Anova du package "car". On obtient les résultats suivants.

```{r , echo=FALSE, warning=FALSE , message=FALSE}

library(car)
Anova(reg, test.statistic = "LR", type = 3)

```

Selon ce test, nous devrions donc garder les variables NCD et VAgeCat.

### Sélection à partir de l'AIC

On peut encore une fois faire une sélection par l'AIC avec la fonction "step". On obtient les résultats suivants : 

```{r , echo=FALSE, warning=FALSE , message=FALSE}

step(reg, direction = "backward")

```

On garde seulement NCD et VAgeCat, qui sont aussi pour ce modèle les deux seules variables significatives.


## GLM Binomiale optimisé

On construit alors le modèle suivant avec les variables sélectionnées précédemment :

```{r , echo=FALSE, warning=FALSE , message=FALSE}

reg_opti <- glm(formula = occurence ~ NCD + VAgeCat , data = data_train, family = binomial(link = "logit"))
summary(reg_opti)

```

Nous avons dans ce modèle un AIC légèrement plus faible que dans le précédent ainsi qu'un plus grand nombre de variables significatives, le modèle est donc bien amélioré de ce point de vue.




# Prédiction

## Prédiction de la survenance ou non d'un sinistre

Une fois les paramètres estimés, on sait que la prédiction est :

$p_i = E[Y_i|X_i=x_i] = P(Y_i=1|X_i=x_i)$   car   $Y_i|X_i$   suit une loi binomiale


De plus, on a :

$g(p_i)=g(E[Y_i|X_i]) = X_i^T\beta$   avec  $g=logit : x \rightarrow log(\frac{x}{1-x})$


Donc : 

$log(\frac{p_i}{1-p_i}) = X_i^T\beta$ d'où $p_i = \frac{exp(X_i^T\beta)}{1+exp(X_i^T\beta)}$


La prédiction obtenue est donc un nombre positif entre 0 et 1. 
Notre objectif est désormais de déterminer un seuil de classification, à partir duquel on pourra trier les prédictions en deux catégories : 

 * $\hat{Y_i}=1$ : l'assuré a eu au moins un sinistre.
 
 * $\hat{Y_i}=0$ : l'assuré n'a pas eu de sinistre. 
 
Nous pourrons alors comparer ces prédictions avec les données réelles des assurés disponible dans la variable "occurence" de la base test.


Un bon moyen de comparer les prédictions avec les données réelles est de les représenter dans une matrice de confusion, qui se présente sous la forme suivante : 

|             | $Y_i =0$           | $Y_i = 1$           |                         
| :------     | ----:              | ----:               |                            
|$\hat{Y_i}=0$| TN = True Negative | FN= False Negative  |           
|$\hat{Y_i}=1$| FP = False Positive| TP = True Positive  | 


On peut également définir les notions de sensibilité et spécificité : 

 * Sensibilité = True Positive Rate (TPR) = $\frac{TP}{TP+FN}$

 * Spécificité = True Negative Rate (TNR) = $\frac{TN}{TN+FP}$ = 1 - False Positive Rate (FPR) = 1 - $\frac{FP}{TN+FP}$

Il n'est pas difficile d'avoir une très bonne sensibilité ou une très bonne spécificité. Il suffit soit de dire que tous les assurés ont eu un sinistre, soit que personne n'en a eu. Un bon test se doit donc d'être à la fois sensible et spécifique.

Intuitivement, on aurait tendance à prendre comme seuil 0,5. Si probabilité est supérieure à 0,5 alors on prend 1 pour la variable occurence à prédire et 0 si inférieur à 0,5. On obtient alors la matrice de confusion suivante :  

```{r, echo=FALSE, warning=FALSE }

pred_bin <- predict(reg_opti, data_test, type="response")

library(caret)

confusionMatrix(as.factor(ifelse(pred_bin > 0.5 ,"1","0")), data_test$occurence, positive = "1")



```

On voit clairement que ce seuil n'est pas adapté puisque tous nos $p_i$ sont inférieur à 0,5. Notre modèle prédit qu'aucun assuré aura un sinistre. La spécificité est ainsi de 100% et la sensibilité de 0%, notre modèle n'a alors aucune utilité.

Un bon moyen de déterminer le seuil optimale est de tracer la courbe ROC qui indique le taux de faux positive (FPR) en fonction du taux de vrai positive (TPR) pour différents seuils de classification.

La courbe ROC relie donc les points (FPR(s), TPR(s)) = (1-Spécificité(s), Sensibilité(s)) obtenus en faisant varier le seuil "s".  

On peut interpréter cette courbe de plusieurs manières. 
  Tout d'abord, si elle coïncide avec la diagonale, le score est aussi performant qu’un modèle aléatoire où l'on attribue la classe au hasard.
  A l'inverse, plus la courbe ROC s’approche du coin supérieur gauche, meilleur est le modèle, car il permet de capturer le plus possible de vrais positifs avec le moins possible de faux positifs.

Ainsi, l’aire sous la courbe ROC, appelée critère AUC, peut être vu comme une mesure de la qualité du score. Ce critère AUC varie entre 0 et 1 et ne dépend pas du seuil choisi. Il peut être vu comme la probabilité pour que la fonction score place un positif devant un négatif. 

En pratique pour choisir le seuil à partir de la courbe ROC, on peut prendre le seuil correspondant au point de la courbe la plus éloigné de la première bissectrice et le plus prêt du point "idéal" supérieur gauche (0, 1).

```{r, echo=FALSE, warning=FALSE }


library(ROCR)
ROCRpred <- prediction(pred_bin, data_test$occurence)
ROCRperf <- performance(ROCRpred, 'tpr','fpr')
plot(ROCRperf, colorize = TRUE)

auc_ROCR <- performance(ROCRpred, measure = "auc")
print (paste0("AUC = ",auc_ROCR@y.values[[1]]))

```

Notre courbe ROC est assez décevante puisqu'elle présente une allure relativement linéaire, et il est difficile d'identifier clairement un seuil optimal. Le seuil semble en tout cas se trouver aux alentours de 0,1. 

Quant à l'AUC, il est égal à environ 0,63. Ainsi, si l'on prend deux assurés, l'un n'ayant pas eu de sinistres et l'autre ayant eu au moins un sinistre. La probabilité que le score de l'assuré avec sinistre soit plus grand que celui sans sinistres est de 63%.

Pour plus de précisions au niveau des seuils, on peut représenter la courbe ROC, seuil par seuil, avec un pas de 0.01 : 


```{r, echo=FALSE , warning=FALSE , message=FALSE}

plot(0:1,0:1,xlab="False Positive Rate", ylab="True Positive Rate",cex=.5)
lines(x = c(0,1), y=c(0,1))

prev=0
for (seuil in seq(0,0.15,by=.01)){
  M=confusionMatrix(as.factor(ifelse(pred_bin > seuil,"1","0")), data_test$occurence, positive = "1")
  TPR = M$byClass["Sensitivity"]
  FPR= 1-M$byClass["Specificity"]
  points(FPR, TPR)
  if (TPR != prev){text(x = FPR, y = TPR, labels = as.character(seuil), pos = 2, cex=0.8)}   #On rajoute du texte que si le point est différents (sinon ce n'est pas lisible)
  prev=TPR
}
```

Le seuil optimal semble être 0.09. On peut s'en assurer avec les boxplots suivants :

```{r, echo=FALSE, warning=FALSE }

box1 <- ggplot(data_test, aes(x = data_test$occurence, y = pred_bin)) +
  geom_boxplot()+
  xlab("Survenance d'un sinistre")+
  ylab("Score de prédicition")+
  ggtitle("Vrai données")

box2 <- ggplot(data_test, aes(x = as.factor(ifelse(pred_bin > 0.09 ,"1","0")), y = pred_bin)) +
  geom_boxplot()+
  xlab("Survenance d'un sinistre")+
  ylab("Score de prédicition")+
  ggtitle("Modèle avec seuil de 0.09")

grid.arrange(box1,box2,nrow=1,ncol=2)
```

Comme on peut le voir sur le premier boxplot, notre score n'est clairement pas idéal, puisqu'il n'arrive pas à séparer la classe "0" de la classe "1". On peut cependant remarquer que le seuil 0.09 semble être un bon choix, puisqu'il permet de capter la première moitié de la classe "1" qui est très concentrée dans cette zone, tout en gardant une bonne partie des "0". 

On peut donc calculer la matrice de confusion avec un seuil de 0.09 : 

```{r, echo=FALSE , warning=FALSE , message=FALSE}

confusionMatrix(as.factor(ifelse(pred_bin > 0.09 ,"1","0")), data_test$occurence, positive = "1")

```

Notre sensibilité et spécificité sont désormais un peu plus équilibré. 
 * Notre sensibilité est de 0,4 : on arrive à prédire correctement 40% du temps si un assuré a eu un sinistre. 
 * Notre spécificité est de 0.76 : on arrive à prédire correctement 76% du temps si un assuré n'a pas eu de sinistres. 
 
 

## Prédiction du nombre de sinistres

Pour un GLM Poisson on sait que : 

$log(E[Y_i|X_i])=X_i^T\beta$


Ainsi la prédiction est égale à : 

$\hat{Y_i} = E[Y_i|X_i] = exp(X_i^T\beta)$


La prédicition nous donne les statistiques suivantes :

```{r, echo=FALSE , warning=FALSE }
pred_pois <- predict(fit_opti, data_test, type="response")
summary(pred_pois)

```

Sur notre jeu de données test, le modèle de Poisson nous dit que les assurés ont une moyenne de 0,07 sinistres. L'assuré le plus à risque aurait en moyenne 0,29 sinistres. 

Le modèle de Poisson ne semble pas très bien adapté à la prédiction, ce qui peut s'expliquer par la grande quantité de personnes qui n'ont pas de sinistres. Ainsi le nombre de 0 est trop largement supérieur au nombre d'entiers strictement positifs. La différence de répartition n'est clairement pas aussi significative dans une loi de Poisson classique. Notre modèle ne prédit donc globalement que des 0.
